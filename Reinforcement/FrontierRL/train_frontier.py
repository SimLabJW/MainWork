"""
train_frontier_v3.py
ê°•í™”í•™ìŠµ ê¸°ë°˜ Frontier ì„ íƒ í•™ìŠµ - ë‹¨ì¼ í™˜ê²½ ìµœì í™” ë²„ì „

ë³€ê²½ ì‚¬í•­:
1. ë³‘ë ¬ í™˜ê²½ ì œê±° (SubprocVecEnv â†’ DummyVecEnv)
2. ë‹¨ì¼ í™˜ê²½ì—ì„œë§Œ í•™ìŠµ ìˆ˜í–‰
3. í•™ìŠµ ìŠ¤í… 10,000ìœ¼ë¡œ ì¶•ì†Œ
4. í‰ê°€ ì£¼ê¸° ë‹¨ì¶• (1,000)
5. reset ê´€ë ¨ ë¬¸ì œ í•´ê²°
"""
import os
import json
import gzip
import base64
import io
import numpy as np
from pathlib import Path
from stable_baselines3 import DQN
from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.monitor import Monitor
from envs.frontier_dqn_env_v3 import FrontierDQNEnv

from stable_baselines3.common.logger import configure

def load_exploration_maps(json_path: str = "exploration_env.json"):
    """
    exploration_env.jsonì—ì„œ ë§µ ë¡œë“œ
    Free(0) â†’ Unknown(-1) ë³€í™˜ ë° ì¢Œí‘œ ì¶”ì 
    """
    import math

    def _infer_hw(n_bytes: int) -> tuple[int, int]:
        best = None
        root = int(math.sqrt(n_bytes))
        for h in range(1, root + 1):
            if n_bytes % h == 0:
                w = n_bytes // h
                score = abs(w - h)
                if (best is None) or (score < best[0]):
                    best = (score, (h, w))
        return best[1] if best else (n_bytes, 1)

    def _decode_one(name: str, md: dict):
        gz_b64 = md["data_gzip_b64"]
        gz_bytes = base64.b64decode(gz_b64)
        with gzip.GzipFile(fileobj=io.BytesIO(gz_bytes), mode="rb") as gz:
            raw = gz.read()
        n = len(raw)

        H = md.get("height")
        W = md.get("width")
        if (H is None) or (W is None) or (int(H) * int(W) != n):
            H, W = _infer_hw(n)
            print(f"â„¹ï¸ [{name}] shape inferred â†’ (H,W)=({H},{W}) from {n} bytes")

        arr_i8 = np.frombuffer(raw, dtype=np.int8).reshape((int(H), int(W))).copy()

        # Free(0) â†’ Unknown(-1) ë³€í™˜
        converted_coords = []
        for i in range(int(H)):
            for j in range(int(W)):
                if arr_i8[i, j] == 0:
                    arr_i8[i, j] = -1
                    converted_coords.append((i, j))

        print(f"âœ… [{name}] {len(converted_coords)} Free cells converted to Unknown")

        # log-odds ë³€í™˜
        logodds = np.zeros((int(H), int(W)), dtype=np.float32)
        logodds[arr_i8 == 0] = -2.0
        logodds[arr_i8 == 100] = +2.0
        logodds[arr_i8 == -1] = 0.0

        origin = md.get("origin", {"x": 0.0, "y": 0.0})
        res = float(md.get("resolution", 0.1))

        return {
            "logodds": logodds,
            "origin_xy": (float(origin.get("x", 0.0)), float(origin.get("y", 0.0))),
            "res": res,
            "converted_coords": converted_coords,
        }

    with open(json_path, "r", encoding="utf-8") as f:
        root = json.load(f)

    maps = {}
    if isinstance(root, dict) and "data_gzip_b64" not in root:
        for k, v in root.items():
            if isinstance(v, dict) and "data_gzip_b64" in v:
                maps[k] = _decode_one(k, v)
        if maps:
            return maps

    raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” exploration_env.json êµ¬ì¡°ìž…ë‹ˆë‹¤.")


def make_env(maps, seed=0, enable_visualization = False):
    """ë‹¨ì¼ í™˜ê²½ ìƒì„± í•¨ìˆ˜"""
    any_map = next(iter(maps.values()))
    env = FrontierDQNEnv(
        maps=maps,
        lidar_max_range_m=40.0,
        ogm_res=any_map["res"],
        occ_thresh=0.65,
        free_thresh=0.35,
        # === ì†ë„ ìµœì í™” ì„¤ì • ===
        max_steps=70,
        top_k_frontiers=5,
        episodes_per_map=50,
        # === ë¦¬ì›Œë“œ ì„¤ì • ===
        reward_info_gain=10.0,
        reward_distance_penalty=-0.1,
        reward_invalid=-5.0,
        # === ë¡œë´‡ ì†ë„ ì„¤ì • ===
        robot_speed_mps=6.0,
        step_dt=0.7,
        lidar_scan_interval_steps=5,
        # === ì‹œê°í™” ë¹„í™œì„±í™” ===
        enable_visualization=enable_visualization,
        seed=seed,
    )
    env = Monitor(env)
    return env


def main():
    # ========== ì„¤ì • ==========
    TOTAL_TIMESTEPS = 10_000   # âœ… ë‹¨ì¼ í•™ìŠµ 1ë§Œ ìŠ¤í…

    # ========== 1. ë§µ ë¡œë“œ ==========
    print("ðŸ“‚ Loading exploration maps...")
    maps = load_exploration_maps("exploration_env.json")
    print(f"âœ… Loaded {len(maps)} maps: {list(maps.keys())}")

    # ========== 2. ë‹¨ì¼ í™˜ê²½ ìƒì„± ==========
    print("\nðŸ—ï¸ Creating single environment...")
    env = DummyVecEnv([lambda: make_env(maps, seed=0, enable_visualization=True)])
    eval_env = DummyVecEnv([lambda: make_env(maps, seed=1, enable_visualization=False)])
    print("âœ… Environment ready (single mode)")

    # ========== 3. DQN ëª¨ë¸ ìƒì„± ==========
    print("\nðŸ§  Creating DQN model...")

    log_dir = "./logs/tensorboard_v2/"
    new_logger = configure(log_dir, ["stdout", "tensorboard"])

    model = DQN(
        policy="MlpPolicy",
        env=env,
        learning_rate=5e-4,
        buffer_size=50_000,
        learning_starts=1_000,
        batch_size=128,
        tau=0.01,
        gamma=0.95,
        train_freq=4,
        gradient_steps=2,
        target_update_interval=500,
        exploration_fraction=0.3,
        exploration_initial_eps=1.0,
        exploration_final_eps=0.05,
        verbose=1,
        tensorboard_log=log_dir,
        policy_kwargs=dict(net_arch=[256, 256, 128]),
    )
    print("âœ… DQN model created")
    model.set_logger(new_logger)

    # ========== 4. ì½œë°± ==========
    checkpoint_dir = "./logs/checkpoints_v2/"
    os.makedirs(checkpoint_dir, exist_ok=True)

    checkpoint_callback = CheckpointCallback(
        save_freq=1_000,
        save_path=checkpoint_dir,
        name_prefix="frontier_dqn_single",
    )

    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path="./logs/best_model_v2/",
        log_path="./logs/eval_v2/",
        eval_freq=1_000,
        n_eval_episodes=3,
        deterministic=True,
        render=False,
    )

    # ========== 5. í•™ìŠµ ==========
    print(f"\nðŸš€ Starting single-environment training for {TOTAL_TIMESTEPS:,} timesteps...")
    model.learn(
        total_timesteps=TOTAL_TIMESTEPS,
        callback=[checkpoint_callback, eval_callback],
        log_interval=100,
        progress_bar=True,
    )

    # ========== 6. ìµœì¢… ì €ìž¥ ==========
    final_model_path = "./logs/final_model_v2/frontier_dqn_single_final"
    os.makedirs("./logs/final_model_v2/", exist_ok=True)
    model.save(final_model_path)
    print(f"\nâœ… Training complete! Model saved to {final_model_path}.zip")

    # ========== 7. í‰ê°€ ==========
    print("\nðŸ“Š Evaluating final model...")
    from stable_baselines3.common.evaluation import evaluate_policy
    mean_reward, std_reward = evaluate_policy(
        model, eval_env, n_eval_episodes=5, deterministic=True
    )
    print(f"  Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}")

    env.close()
    eval_env.close()
    print("\nðŸŽ‰ All done!")


if __name__ == "__main__":
    main()
